<h1 align="center">FlagEmbedding</h1>
<p align="center">
    <a href="https://www.python.org/">
            <img alt="Build" src="https://img.shields.io/badge/Made with-Python-purple">
    </a>
    <a href="https://github.com/FlagOpen/FlagEmbedding/blob/master/LICENSE">
        <img alt="License" src="https://img.shields.io/badge/LICENSE-MIT-green">
    </a>
    <a href="https://huggingface.co/C-MTEB">
        <img alt="License" src="https://img.shields.io/badge/C_MTEB-ğŸ¤—-yellow">
    </a>
    <a href="https://github.com/FlagOpen/FlagEmbedding/tree/master/FlagEmbedding">
        <img alt="License" src="https://img.shields.io/badge/universal embedding-1.1-red">
    </a>
</p>

<h4 align="center">
    <p>
        <a href=#model-list>æ¨¡å‹åˆ—è¡¨</a> | 
        <a href=#å¸¸è§é—®é¢˜>å¸¸è§é—®é¢˜</a> | 
        <a href=#usage>ä½¿ç”¨æ–¹æ³•</a>  |
        <a href="#evaluation">æ¨¡å‹è¯„ä¼°</a> |
        <a href="#train">æ¨¡å‹è®­ç»ƒ</a> |
        <a href="#contact">Contact</a> |
        <a href="#citation">Citation</a> |
        <a href="#license">License</a> 
    <p>
</h4>

[English](README.md) | [ä¸­æ–‡](README_zh.md)


å°†ä»»æ„æ–‡æœ¬æ˜ å°„ä¸ºä½ç»´ç¨ å¯†å‘é‡ï¼Œä»¥ç”¨äºæ£€ç´¢ã€åˆ†ç±»ã€èšç±»æˆ–è¯­ä¹‰åŒ¹é…ç­‰ä»»åŠ¡ï¼Œå¹¶å¯æ”¯æŒä¸ºå¤§æ¨¡å‹è°ƒç”¨å¤–éƒ¨çŸ¥è¯†ã€‚

************* ğŸŒŸ**Updates**ğŸŒŸ *************
- 10/12/2023: å‘å¸ƒ [LLM-Embedder](https://github.com/FlagOpen/FlagEmbedding/tree/master/FlagEmbedding/llm_embedder), ä¸“ä¸ºå¤§è¯­è¨€æ¨¡å‹**å„ç§æ£€ç´¢å¢å¼ºä»»åŠ¡è®¾è®¡**çš„è‹±æ–‡å‘é‡æ¨¡å‹ã€‚[è®ºæ–‡é“¾æ¥](https://arxiv.org/pdf/2310.07554.pdf) :fire:
- 09/15/2023: å‘å¸ƒ [è®ºæ–‡](https://arxiv.org/pdf/2309.07597.pdf) å’Œ [æ•°æ®é›†](https://data.baai.ac.cn/details/BAAI-MTP).
- 09/12/2023: æ›´æ–°ï¼š
    - **æ–°å¢é‡æ’æ¨¡å‹**ï¼šå¼€æºäº¤å‰ç¼–ç å™¨æ¨¡å‹bge-rerankerï¼Œå…·æœ‰æ¯”å‘é‡æ¨¡å‹æ›´å¼ºå¤§çš„æ’åºèƒ½åŠ›ã€‚éå¸¸å»ºè®®ä½¿ç”¨æˆ–è€…å¾®è°ƒå®ƒæ¥é‡æ–°æ’åºå‘é‡æ¨¡å‹è¿”å›çš„top-kæ–‡æ¡£ï¼Œæé«˜æœ€ç»ˆç»“æœçš„ç›¸å…³æ€§ã€‚
    - **æ›´æ–°å‘é‡æ¨¡å‹**ï¼šå‘å¸ƒbge-*-v1.5å‘é‡æ¨¡å‹ï¼Œç¼“è§£ç›¸ä¼¼åº¦åˆ†å¸ƒé—®é¢˜ï¼Œæå‡æ— æŒ‡ä»¤æƒ…å†µä¸‹çš„æ£€ç´¢èƒ½åŠ›ï¼ˆä½†æ£€ç´¢ä»»åŠ¡ä»å»ºè®®ä½¿ç”¨æŒ‡ä»¤ï¼‰
- 09/07/2023: æ›´æ–°[å¾®è°ƒä»£ç ](https://github.com/FlagOpen/FlagEmbedding/blob/master/FlagEmbedding/baai_general_embedding/README.md): å¢åŠ éš¾è´Ÿæ ·æœ¬æŒ–æ˜è„šæœ¬ï¼Œå¢åŠ æŒ‡ä»¤å‚æ•°æ–¹ä¾¿åœ¨å¾®è°ƒä¸­æ·»åŠ æŒ‡ä»¤.
- 08/09/2023: BGEæ¨¡å‹æ•´åˆå…¥Langchain, å¯ä»¥åœ¨langchainä¸­éå¸¸ç®€å•çš„[ä½¿ç”¨å®ƒ](#using-langchain); C-MTEBä¸­æ–‡æ¦œå•å·²[åœ¨çº¿æ›´æ–°](https://huggingface.co/spaces/mteb/leaderboard).  
- 08/05/2023: å‘å¸ƒæ›´å°çš„æ¨¡å‹(base, small), **åœ¨åŒå°ºå¯¸æ¨¡å‹ä¸­å–å¾—æœ€å¥½çš„æ€§èƒ½ï¼ ğŸ¤—**
- 08/02/2023: :tada: :tada: å‘å¸ƒä¸­è‹±æ–‡å‘é‡æ¨¡å‹BGE(BAAI General Embeddingçš„ç¼©å†™), **åœ¨MTEBå’ŒC-MTEBæ¦œå•ä¸Šå–å¾—æœ€å¥½çš„æ€§èƒ½** 
- 08/01/2023: å‘å¸ƒå¤§è§„æ¨¡ä¸­æ–‡æ–‡æœ¬å‘é‡[è¯„æµ‹æ¦œå•](https://github.com/FlagOpen/FlagEmbedding/blob/master/C_MTEB) (**C-MTEB**), å…¶åŒ…æ‹¬31ä¸ªæµ‹è¯•ä»»åŠ¡.   




## Model List
|              Model              | Language | | Description | query instruction for retrieval [1] |
|:-------------------------------|:--------:| :--------:| :--------:|:--------:|
|  [BAAI/llm-embedder](https://huggingface.co/BAAI/llm-embedder)  |   English | [æ¨ç†](https://github.com/FlagOpen/FlagEmbedding/tree/master/FlagEmbedding/llm_embedder) [å¾®è°ƒ](https://github.com/FlagOpen/FlagEmbedding/tree/master/FlagEmbedding/llm_embedder) | ä¸“ä¸ºå¤§è¯­è¨€æ¨¡å‹å„ç§æ£€ç´¢å¢å¼ºä»»åŠ¡è®¾è®¡çš„å‘é‡æ¨¡å‹  | è¯¦è§ [README](https://github.com/FlagOpen/FlagEmbedding/tree/master/FlagEmbedding/llm_embedder) |
|  [BAAI/bge-reranker-large](https://huggingface.co/BAAI/bge-reranker-large) |   Chinese and English | [æ¨ç†](#usage-for-reranker) [å¾®è°ƒ](https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/reranker) | äº¤å‰ç¼–ç å™¨æ¨¡å‹ï¼Œç²¾åº¦æ¯”å‘é‡æ¨¡å‹æ›´é«˜ä½†æ¨ç†æ•ˆç‡è¾ƒä½ [2] |   |
|  [BAAI/bge-reranker-base](https://huggingface.co/BAAI/bge-reranker-base) |   Chinese and English | [æ¨ç†](#usage-for-reranker) [å¾®è°ƒ](https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/reranker) | äº¤å‰ç¼–ç å™¨æ¨¡å‹ï¼Œç²¾åº¦æ¯”å‘é‡æ¨¡å‹æ›´é«˜ä½†æ¨ç†æ•ˆç‡è¾ƒä½ [2] |   |
|  [BAAI/bge-large-en-v1.5](https://huggingface.co/BAAI/bge-large-en-v1.5) |   English | [æ¨ç†](#usage-for-embedding-model) [å¾®è°ƒ](https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune) | 1.5ç‰ˆæœ¬ï¼Œç›¸ä¼¼åº¦åˆ†å¸ƒæ›´åŠ åˆç† | `Represent this sentence for searching relevant passages: `  |
|  [BAAI/bge-base-en-v1.5](https://huggingface.co/BAAI/bge-base-en-v1.5) |   English | [æ¨ç†](#usage-for-embedding-model) [å¾®è°ƒ](https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune) | 1.5ç‰ˆæœ¬ï¼Œç›¸ä¼¼åº¦åˆ†å¸ƒæ›´åŠ åˆç† | `Represent this sentence for searching relevant passages: `  |
|  [BAAI/bge-small-en-v1.5](https://huggingface.co/BAAI/bge-small-en-v1.5) |   English | [æ¨ç†](#usage-for-embedding-model) [å¾®è°ƒ](https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune) | 1.5ç‰ˆæœ¬ï¼Œç›¸ä¼¼åº¦åˆ†å¸ƒæ›´åŠ åˆç† | `Represent this sentence for searching relevant passages: `  |
|  [BAAI/bge-large-zh-v1.5](https://huggingface.co/BAAI/bge-large-zh-v1.5) |   Chinese | [æ¨ç†](#usage-for-embedding-model) [å¾®è°ƒ](https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune) | 1.5ç‰ˆæœ¬ï¼Œç›¸ä¼¼åº¦åˆ†å¸ƒæ›´åŠ åˆç† | `ä¸ºè¿™ä¸ªå¥å­ç”Ÿæˆè¡¨ç¤ºä»¥ç”¨äºæ£€ç´¢ç›¸å…³æ–‡ç« ï¼š`  |
|  [BAAI/bge-base-zh-v1.5](https://huggingface.co/BAAI/bge-base-zh-v1.5) |   Chinese |  [æ¨ç†](#usage-for-embedding-model) [å¾®è°ƒ](https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune) | 1.5ç‰ˆæœ¬ï¼Œç›¸ä¼¼åº¦åˆ†å¸ƒæ›´åŠ åˆç† | `ä¸ºè¿™ä¸ªå¥å­ç”Ÿæˆè¡¨ç¤ºä»¥ç”¨äºæ£€ç´¢ç›¸å…³æ–‡ç« ï¼š`  |
|  [BAAI/bge-small-zh-v1.5](https://huggingface.co/BAAI/bge-small-zh-v1.5) |   Chinese | [æ¨ç†](#usage-for-embedding-model) [å¾®è°ƒ](https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune) | 1.5ç‰ˆæœ¬ï¼Œç›¸ä¼¼åº¦åˆ†å¸ƒæ›´åŠ åˆç† | `ä¸ºè¿™ä¸ªå¥å­ç”Ÿæˆè¡¨ç¤ºä»¥ç”¨äºæ£€ç´¢ç›¸å…³æ–‡ç« ï¼š`  |
|  [BAAI/bge-large-en](https://huggingface.co/BAAI/bge-large-en) |   English | [æ¨ç†](#usage-for-embedding-model) [å¾®è°ƒ](https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune) |  :trophy:  SOTAæ€§èƒ½åœ¨ [MTEB](https://huggingface.co/spaces/mteb/leaderboard) æ¦œå• | `Represent this sentence for searching relevant passages: `  |
|  [BAAI/bge-base-en](https://huggingface.co/BAAI/bge-base-en) |   English | [æ¨ç†](#usage-for-embedding-model) [å¾®è°ƒ](https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune) | base-scale æ¨¡å‹ | `Represent this sentence for searching relevant passages: `  |
|  [BAAI/bge-small-en](https://huggingface.co/BAAI/bge-small-en) |   English | [æ¨ç†](#usage-for-embedding-model) [å¾®è°ƒ](https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune) | small-scale æ¨¡å‹  | `Represent this sentence for searching relevant passages: `  |
|  [BAAI/bge-large-zh](https://huggingface.co/BAAI/bge-large-zh) |   Chinese | [æ¨ç†](#usage-for-embedding-model) [å¾®è°ƒ](https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune) | :trophy: SOTAæ€§èƒ½åœ¨ [C-MTEB](https://github.com/FlagOpen/FlagEmbedding/tree/master/C_MTEB) æ¦œå• | `ä¸ºè¿™ä¸ªå¥å­ç”Ÿæˆè¡¨ç¤ºä»¥ç”¨äºæ£€ç´¢ç›¸å…³æ–‡ç« ï¼š`  |
|  [BAAI/bge-base-zh](https://huggingface.co/BAAI/bge-base-zh) |   Chinese |  [æ¨ç†](#usage-for-embedding-model) [å¾®è°ƒ](https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune) | base-scale æ¨¡å‹ | `ä¸ºè¿™ä¸ªå¥å­ç”Ÿæˆè¡¨ç¤ºä»¥ç”¨äºæ£€ç´¢ç›¸å…³æ–‡ç« ï¼š`  |
|  [BAAI/bge-small-zh](https://huggingface.co/BAAI/bge-small-zh) |   Chinese | [æ¨ç†](#usage-for-embedding-model) [å¾®è°ƒ](https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune) | small-scaleæ¨¡å‹ | `ä¸ºè¿™ä¸ªå¥å­ç”Ÿæˆè¡¨ç¤ºä»¥ç”¨äºæ£€ç´¢ç›¸å…³æ–‡ç« ï¼š`  |


[1\]: å¦‚æœæ‚¨éœ€è¦ä¸ºä¸€ä¸ª**ç®€çŸ­çš„æŸ¥è¯¢æœç´¢ç›¸å…³çš„æ–‡æ¡£**ï¼Œæ‚¨éœ€è¦åœ¨æŸ¥è¯¢ä¸­æ·»åŠ æŒ‡ä»¤ï¼›åœ¨å…¶ä»–æƒ…å†µä¸‹ï¼Œä¸éœ€è¦æŒ‡ä»¤ï¼Œç›´æ¥ä½¿ç”¨åŸå§‹æŸ¥è¯¢å³å¯ã€‚åœ¨ä»»ä½•æƒ…å†µä¸‹ï¼Œæ‚¨éƒ½**ä¸éœ€è¦ä¸ºå€™é€‰æ–‡æ¡£å¢åŠ æŒ‡ä»¤**ã€‚

[2\]: ä¸åŒäºå‘é‡æ¨¡å‹è¾“å‡ºå‘é‡ï¼Œrerankeräº¤å‰ç¼–ç å™¨ä½¿ç”¨é—®é¢˜å’Œæ–‡æ¡£ä½œä¸ºè¾“å…¥ï¼Œç›´æ¥è¾“å‡ºç›¸ä¼¼åº¦ã€‚ä¸ºäº†å¹³è¡¡å‡†ç¡®ç‡å’Œæ—¶é—´æˆæœ¬ï¼Œäº¤å‰ç¼–ç å™¨ä¸€èˆ¬ç”¨äºå¯¹å…¶ä»–ç®€å•æ¨¡å‹æ£€ç´¢åˆ°çš„top-kæ–‡æ¡£è¿›è¡Œé‡æ’åºã€‚ä¾‹å¦‚ï¼Œä½¿ç”¨bgeå‘é‡æ¨¡å‹æ£€ç´¢å‰100ä¸ªç›¸å…³æ–‡æ¡£ï¼Œç„¶åä½¿ç”¨bge rerankerå¯¹å‰100ä¸ªæ–‡æ¡£é‡æ–°æ’åºï¼Œå¾—åˆ°æœ€ç»ˆçš„top-3ç»“æœã€‚

## å¸¸è§é—®é¢˜

**1. å¦‚ä½•å¾®è°ƒbgeæ¨¡å‹**

éµå¾ªè¿™ä¸ª[ç¤ºä¾‹](https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune) æ¥å‡†å¤‡æ•°æ®å¹¶å¾®è°ƒæ¨¡å‹ã€‚
ä¸€äº›å»ºè®®ï¼š
- æŒ‰ç…§è¿™ä¸ª[å‘½ä»¤](https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune#hard-negatives) æŒ–æ˜éš¾è´Ÿæ ·æœ¬ï¼Œè¿™å¯ä»¥æ˜æ˜¾æé«˜æ£€ç´¢æ€§èƒ½ã€‚
- é€šå¸¸ï¼Œ`per_device_train_batch_size`å‚æ•°è¶Šå¤§è¶Šå¥½ï¼Œå…¶å¯ä»¥å¢å¤§In-batch negativesçš„æ•°é‡ã€‚å¯ä»¥é€šè¿‡å¼€å¯`--fp16`, `--deepspeed df_config.json`(df_config.jsonè¯·å‚è€ƒ [ds_config.json](./ds_config.json)), `--gradient_checkpointing`ç­‰æ–¹å¼æ¥æ‹“å±•batch sizeã€‚
- `train_group_size` å‚æ•°åœ¨æˆ‘ä»¬å®éªŒä¸­ï¼ˆä½¿ç”¨äº†éš¾è´Ÿæ ·æœ¬ï¼‰é»˜è®¤è®¾ä¸º8ã€‚å¯ä»¥æ ¹æ®æ•°æ®ä¸­çš„å¹³å‡è´Ÿæ ·æœ¬æ•°æ®è¿›è¡Œè®¾ç½®ï¼štrain_group_size=è´Ÿæ ·æœ¬æ•°é‡+1ã€‚
- `query_max_len` å’Œ`passage_max_len`å‚æ•°åº”è¯¥æŒ‰ç…§å®é™…æ•°æ®é•¿åº¦è¿›è¡Œè®¾ç½®ï¼Œæ•°æ®éƒ½å¾ˆé•¿çš„è¯åº”è¯¥å¢å¤§ï¼Œä½†ä¸èƒ½è¶…è¿‡512ã€‚
- å¦‚æœå¾®è°ƒå‘é‡æ¨¡å‹çš„å‡†ç¡®ç‡ä»ç„¶ä¸é«˜ï¼Œå»ºè®®ä½¿ç”¨æˆ–è€…å¾®è°ƒäº¤å‰ç¼–ç å™¨æ¨¡å‹(bge-reranker)å¯¹top-kç»“æœè¿›è¡Œé‡æ–°æ’åºã€‚
äº¤å‰ç¼–ç å™¨æ¨¡å‹çš„æ•°æ®æ ¼å¼ä¸å‘é‡æ¨¡å‹ä¸€è‡´ï¼ŒåŒæ—¶ä¹Ÿå»ºè®®ä½¿ç”¨éš¾è´Ÿæ ·æœ¬ã€‚åœ¨æ­£ç¡®å¾®è°ƒçš„æƒ…å†µä¸‹ï¼Œäº¤å‰ç¼–ç å™¨æ¨¡å‹çš„å‡†ç¡®åº¦ä¼šé«˜äºå‘é‡æ¨¡å‹ã€‚
- å¦‚æœè¿›è¡Œäº†é¢„è®­ç»ƒï¼Œé¢„è®­ç»ƒåçš„æ¨¡å‹æ— æ³•ç›´æ¥ç”¨äºè®¡ç®—ç›¸ä¼¼åº¦ï¼Œå¿…é¡»ç»è¿‡å¾®è°ƒæ‰èƒ½è¿›è¡Œç›¸ä¼¼åº¦ã€‚




<details>
  <summary>2. ä¸ç›¸ä¼¼å¥å­ä¹‹é—´çš„ç›¸ä¼¼åº¦åˆ†æ•°å¾ˆé«˜ </summary>

  <!-- ### ä¸ç›¸ä¼¼å¥å­ä¹‹é—´çš„ç›¸ä¼¼åº¦åˆ†æ•°å¾ˆé«˜ -->
**å»ºè®®ä½¿ç”¨bge v1.5ï¼Œå®ƒç¼“è§£äº†ç›¸ä¼¼åº¦åˆ†å¸ƒçš„é—®é¢˜ã€‚** 

ç”±äºæˆ‘ä»¬é€šè¿‡æ¸©åº¦ä¸º0.01çš„å¯¹æ¯”å­¦ä¹ æ¥å¾®è°ƒæ¨¡å‹ï¼Œ
å½“å‰BGEæ¨¡å‹çš„ç›¸ä¼¼åº¦åˆ†å¸ƒå¤§çº¦åœ¨\[0.6, 1\]åŒºé—´å†…ã€‚
å› æ­¤ï¼Œç›¸ä¼¼åº¦å¤§äº0.6å¹¶ä¸è¡¨ç¤ºè¿™ä¸¤ä¸ªå¥å­ç›¸ä¼¼ã€‚

å¯¹äºä¸‹æ¸¸ä»»åŠ¡ï¼Œå¦‚æ®µè½æ£€ç´¢æˆ–è¯­ä¹‰ç›¸ä¼¼æ€§ï¼Œ
**é‡è¦çš„æ˜¯åˆ†æ•°çš„ç›¸å¯¹é¡ºåºï¼Œè€Œä¸æ˜¯ç»å¯¹å€¼ã€‚**
å¦‚æœä½ éœ€è¦æ ¹æ®ç›¸ä¼¼åº¦é˜ˆå€¼è¿‡æ»¤ç›¸ä¼¼å¥å­ï¼Œ
è¯·æ ¹æ®æ•°æ®çš„ç›¸ä¼¼åº¦åˆ†å¸ƒ(å¦‚0.8,0.85ï¼Œç”šè‡³0.9)é€‰æ‹©åˆé€‚çš„ç›¸ä¼¼åº¦é˜ˆå€¼ã€‚

</details>


<details>
  <summary>3. ä»€ä¹ˆæ—¶å€™éœ€è¦æ·»åŠ æŸ¥è¯¢æŒ‡ä»¤ </summary>

  <!-- ### ä»€ä¹ˆæ—¶å€™éœ€è¦æ·»åŠ æŸ¥è¯¢æŒ‡ä»¤ -->
å¯¹äº`bge-*-v1.5`ï¼Œæˆ‘ä»¬æé«˜äº†å®ƒåœ¨ä¸ä½¿ç”¨æŒ‡ä»¤æ—¶çš„æ£€ç´¢èƒ½åŠ›ã€‚æ— æŒ‡ä»¤æ£€ç´¢æ€§èƒ½ä»…æ¯”ä½¿ç”¨æŒ‡ä»¤æ£€ç´¢æ€§èƒ½ç•¥æœ‰ä¸‹é™ã€‚
å› æ­¤ï¼Œå¦‚æœæƒ³è¦æ›´åŠ æ–¹ä¾¿çš„è¯ï¼Œæ‚¨åœ¨æ‰€æœ‰æƒ…å†µä¸‹éƒ½å¯ä»¥åœ¨æ²¡æœ‰æŒ‡ä»¤çš„æƒ…å†µä¸‹ç”Ÿæˆå‘é‡ã€‚

å¯¹äºä¸€ä¸ªä½¿ç”¨çŸ­æŸ¥è¯¢å¯»æ‰¾ç›¸å…³é•¿æ–‡æ¡£çš„æ£€ç´¢ä»»åŠ¡ï¼ŒæŸ¥è¯¢ä¸æ–‡æ¡£ä¹‹é—´é•¿åº¦éå¸¸ä¸ä¸€è‡´ï¼Œæ¨èä¸ºçŸ­æŸ¥è¯¢æ·»åŠ æŒ‡ä»¤ã€‚å…¶ä»–ä»»åŠ¡ï¼Œæ¨èä¸æ·»åŠ æŒ‡ä»¤ã€‚
**æœ€å¥½çš„é€‰æ‹©æ–¹å¼ï¼Œæ˜¯æ ¹æ®å®é™…æƒ…å†µé€‰æ‹©å…¶ä¸­è¡¨ç°æœ€å¥½çš„æ–¹å¼ã€‚**
åœ¨æ‰€æœ‰æƒ…å†µä¸‹ï¼Œæ–‡æ¡£ç«¯éƒ½ä¸ç”¨æ·»åŠ æŒ‡ä»¤ï¼Œåªæ˜¯æŸ¥è¯¢ç«¯å¯ä»¥é€‰æ‹©æ˜¯å¦æ·»åŠ æŒ‡ä»¤ã€‚

</details>





## Usage 

### Usage for Embedding Model

è¿™é‡Œå±•ç¤ºäº†ä¸€äº›é€šè¿‡
[FlagEmbedding](#using-flagembedding), [Sentence-Transformers](#using-sentence-transformers), [Langchain](#using-langchain), or [Huggingface Transformers](#using-huggingface-transformers).
ä½¿ç”¨`bge`æ¨¡å‹çš„æ–¹æ³•ã€‚

#### Using FlagEmbedding
```
pip install -U FlagEmbedding
```
å¦‚æœæ‚¨ä½¿ç”¨äº†é•œåƒï¼Œå¯èƒ½æ— æ³•æ‰¾åˆ°æœ€æ–°ç‰ˆçš„FlagEmbeddingã€‚
å¯ä»¥å‚è€ƒ[FlagEmbedding](https://github.com/FlagOpen/FlagEmbedding/blob/master/FlagEmbedding/baai_general_embedding/README.md) ä¸‹è½½æ”¹é¡¹ç›®è¿›è¡Œå®‰è£…ã€‚


```python
from FlagEmbedding import FlagModel
sentences = ["æ ·ä¾‹æ•°æ®-1", "æ ·ä¾‹æ•°æ®-2"]
model = FlagModel('BAAI/bge-large-zh-v1.5', 
                  query_instruction_for_retrieval="ä¸ºè¿™ä¸ªå¥å­ç”Ÿæˆè¡¨ç¤ºä»¥ç”¨äºæ£€ç´¢ç›¸å…³æ–‡ç« ï¼š",
                  use_fp16=True) # è®¾ç½®use_fp16ä¸ºTrueå¯ä»¥åŠ å¿«è®¡ç®—ï¼Œæ•ˆæœä¼šç¨æœ‰ä¸‹é™
embeddings_1 = model.encode(sentences)
embeddings_2 = model.encode(sentences)
similarity = embeddings_1 @ embeddings_2.T
print(similarity)

# å¯¹äºçŸ­æŸ¥è¯¢åˆ°é•¿æ–‡æ¡£çš„æ£€ç´¢ä»»åŠ¡ï¼Œè¯·å¯¹æŸ¥è¯¢ä½¿ç”¨ encode_queries() å‡½æ•°ï¼Œå…¶ä¼šè‡ªåŠ¨ä¸ºæ¯ä¸ªæŸ¥è¯¢åŠ ä¸ŠæŒ‡ä»¤
# ç”±äºå€™é€‰æ–‡æœ¬ä¸éœ€è¦æ·»åŠ æŒ‡ä»¤ï¼Œæ£€ç´¢ä¸­çš„å€™é€‰é›†ä¾ç„¶ä½¿ç”¨ encode() æˆ– encode_corpus() å‡½æ•°
queries = ['query_1', 'query_2']
passages = ["æ ·ä¾‹æ–‡æ¡£-1", "æ ·ä¾‹æ–‡æ¡£-2"]
q_embeddings = model.encode_queries(queries)
p_embeddings = model.encode(passages)
scores = q_embeddings @ p_embeddings.T
```
Instructionå‚æ•° `query_instruction_for_retrieval` è¯·å‚ç…§ï¼š [Model List](https://github.com/FlagOpen/FlagEmbedding/tree/master#model-list). 
å½“åŠ è½½ä½ å¾®è°ƒåçš„æ¨¡å‹æ—¶ï¼Œå¦‚æœä½ æ²¡æœ‰åœ¨è®­ç»ƒçš„jsonæ–‡ä»¶ä¸­ä¸ºqueryæ·»åŠ æŒ‡ä»¤ï¼Œåˆ™å°†å…¶è®¾ç½®ä¸ºç©ºå­—ç¬¦ä¸²`""`; å¦‚æœä½ åœ¨è®­ç»ƒæ•°æ®ä¸­ä¸ºqueryæ·»åŠ äº†æŒ‡ä»¤ï¼Œæ›´æ”¹ä¸ºä½ æ–°è®¾ç½®çš„æŒ‡ä»¤ã€‚

FlagModelæ”¯æŒGPUä¹Ÿæ”¯æŒCPUæ¨ç†ã€‚å¦‚æœGPUå¯ç”¨ï¼Œå…¶é»˜è®¤ä¼˜å…ˆä½¿ç”¨GPUã€‚å¦‚æœæƒ³ç¦æ­¢å…¶ä½¿ç”¨GPUï¼Œè®¾ç½®`os.environ["CUDA_VISIBLE_DEVICES"]=""`
ä¸ºæé«˜æ•ˆç‡ï¼ŒFlagModelé»˜è®¤ä¼šä½¿ç”¨æ‰€æœ‰çš„GPUè¿›è¡Œæ¨ç†ã€‚å¦‚æœæƒ³è¦ä½¿ç”¨å…·ä½“çš„GPUï¼Œè¯·è®¾ç½®`os.environ["CUDA_VISIBLE_DEVICES"]`ã€‚


#### Using Sentence-Transformers

å®‰è£… [sentence-transformers](https://www.SBERT.net):

```
pip install -U sentence-transformers
```

åŸºäºSentence-Transformersçš„ä½¿ç”¨æ–¹æ³•:

```python
from sentence_transformers import SentenceTransformer
sentences = ["æ ·ä¾‹æ•°æ®-1", "æ ·ä¾‹æ•°æ®-2"]
model = SentenceTransformer('BAAI/bge-large-zh-v1.5')
embeddings_1 = model.encode(sentences, normalize_embeddings=True)
embeddings_2 = model.encode(sentences, normalize_embeddings=True)
similarity = embeddings_1 @ embeddings_2.T
print(similarity)
```
å¯¹äºçŸ­æŸ¥è¯¢åˆ°é•¿æ–‡æ¡£çš„æ£€ç´¢ä»»åŠ¡ï¼Œ
æ¯ä¸ªæŸ¥è¯¢éƒ½åº”è¯¥ä»¥ä¸€æ¡æŒ‡ä»¤å¼€å§‹(æŒ‡ä»¤å‚è€ƒ [Model List](https://github.com/FlagOpen/FlagEmbedding/tree/master#model-list)). 
ä½†å¯¹äºæ–‡æ¡£ï¼Œä¸éœ€è¦æ·»åŠ ä»»ä½•æŒ‡ä»¤ã€‚
```python
queries = ['query_1', 'query_2']
passages = ["æ ·ä¾‹æ–‡æ¡£-1", "æ ·ä¾‹æ–‡æ¡£-2"]
instruction = "ä¸ºè¿™ä¸ªå¥å­ç”Ÿæˆè¡¨ç¤ºä»¥ç”¨äºæ£€ç´¢ç›¸å…³æ–‡ç« ï¼š"
model = SentenceTransformer('BAAI/bge-large-zh-v1.5')
q_embeddings = model.encode([instruction+q for q in queries], normalize_embeddings=True)
p_embeddings = model.encode(passages, normalize_embeddings=True)
scores = q_embeddings @ p_embeddings.T
```
å¦‚æœæƒ³ä½¿ç”¨sentence_transformersåŠ è½½ä½ å¾®è°ƒåçš„æ¨¡å‹ï¼Œå¯ä»¥å‚è€ƒ[è¿™é‡Œ](https://github.com/FlagOpen/FlagEmbedding/tree/master/FlagEmbedding/baai_general_embedding#3-load-your-model) ã€‚
åŒæ—¶ï¼Œå¯¹äº`instruction`, å¦‚æœä½ æ²¡æœ‰åœ¨è®­ç»ƒçš„jsonæ–‡ä»¶ä¸­ä¸ºqueryæ·»åŠ æŒ‡ä»¤ï¼Œåˆ™å°†å…¶è®¾ç½®ä¸ºç©ºå­—ç¬¦ä¸²`""`; å¦‚æœä½ åœ¨è®­ç»ƒæ•°æ®ä¸­ä¸ºqueryæ·»åŠ äº†æŒ‡ä»¤ï¼Œæ›´æ”¹ä¸ºä½ æ–°è®¾ç½®çš„æŒ‡ä»¤ã€‚


#### Using Langchain

åœ¨Langchianä¸­ä½¿ç”¨bgeæ¨¡å‹ï¼š
```python
from langchain.embeddings import HuggingFaceBgeEmbeddings
model_name = "BAAI/bge-large-en-v1.5"
model_kwargs = {'device': 'cpu'}
encode_kwargs = {'normalize_embeddings': True} # set True to compute cosine similarity
model = HuggingFaceBgeEmbeddings(
    model_name=model_name,
    model_kwargs=model_kwargs,
    encode_kwargs=encode_kwargs
)
```

#### Using HuggingFace Transformers

ä½¿ç”¨transformersåº“æ—¶ï¼Œæ‚¨å¯ä»¥è¿™æ ·ä½¿ç”¨æ¨¡å‹:é¦–å…ˆï¼Œå°†è¾“å…¥ä¼ é€’ç»™transformeræ¨¡å‹ï¼Œç„¶åé€‰æ‹©ç¬¬ä¸€ä¸ªæ ‡è®°çš„æœ€åä¸€ä¸ªéšè—çŠ¶æ€(å³[CLS])ä½œä¸ºå¥å­åµŒå…¥ã€‚
```python
from transformers import AutoTokenizer, AutoModel
import torch
# Sentences we want sentence embeddings for
sentences = ["æ ·ä¾‹æ•°æ®-1", "æ ·ä¾‹æ•°æ®-2"]

# Load model from HuggingFace Hub
tokenizer = AutoTokenizer.from_pretrained('BAAI/bge-large-zh-v1.5')
model = AutoModel.from_pretrained('BAAI/bge-large-zh-v1.5')

# Tokenize sentences
encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')
# å¯¹äºçŸ­æŸ¥è¯¢åˆ°é•¿æ–‡æ¡£çš„æ£€ç´¢ä»»åŠ¡, ä¸ºæŸ¥è¯¢åŠ ä¸ŠæŒ‡ä»¤
# encoded_input = tokenizer([instruction + q for q in queries], padding=True, truncation=True, return_tensors='pt')

# Compute embeddings
with torch.no_grad():
    model_output = model(**encoded_input)
    # Perform pooling. In this case, cls pooling.
    sentence_embeddings = model_output[0][:, 0]
# normalize embeddings
sentence_embeddings = torch.nn.functional.normalize(sentence_embeddings, p=2, dim=1)
print("Sentence embeddings:", sentence_embeddings)
```


### Usage for Reranker

ä¸åŒäºå‘é‡æ¨¡å‹ï¼Œrerankeræ— æ³•å¯¹å•ä¸ªæ–‡æœ¬è¾“å‡ºå‘é‡ï¼Œå…¶éœ€è¦è¾“å…¥ä¸€ä¸ªæ–‡æœ¬å¯¹ç›´æ¥è®¡ç®—åˆ†æ•°ã€‚
ä½ å¯ä»¥é€šè¿‡åœ¨rerankerä¸­è¾“å…¥queryå’Œpassageæ¥è·å¾—ç›¸å…³åº¦åˆ†æ•°ï¼Œåˆ†æ•°è¶Šé«˜ä»£è¡¨è¶Šç›¸å…³ã€‚
è¯¥é‡æ’åºå™¨åŸºäºäº¤å‰ç†µæŸå¤±è¿›è¡Œä¼˜åŒ–ï¼Œå› æ­¤ç›¸å…³æ€§åˆ†æ•°æ²¡æœ‰ä¸€ä¸ªç‰¹å®šçš„æ•°å€¼èŒƒå›´ã€‚

#### Using FlagEmbedding
```
pip install -U FlagEmbedding
```

è®¡ç®—ç›¸å…³åˆ†æ•°ï¼Œè¶Šé«˜è¡¨ç¤ºè¶Šç›¸å…³:
```python
from FlagEmbedding import FlagReranker
reranker = FlagReranker('BAAI/bge-reranker-large', use_fp16=True) #è®¾ç½® fp16 ä¸ºTrueå¯ä»¥åŠ å¿«æ¨ç†é€Ÿåº¦ï¼Œæ•ˆæœä¼šæœ‰å¯ä»¥å¿½ç•¥çš„ä¸‹é™

score = reranker.compute_score(['query', 'passage']) # è®¡ç®— query å’Œ passageçš„ç›¸ä¼¼åº¦
print(score)

scores = reranker.compute_score([['query 1', 'passage 1'], ['query 2', 'passage 2']])
print(scores)
```


#### Using Huggingface transformers

```python
import torch
from transformers import AutoModelForSequenceClassification, AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained('BAAI/bge-reranker-large')
model = AutoModelForSequenceClassification.from_pretrained('BAAI/bge-reranker-large')
model.eval()

pairs = [['what is panda?', 'hi'], ['what is panda?', 'The giant panda (Ailuropoda melanoleuca), sometimes called a panda bear or simply panda, is a bear species endemic to China.']]
with torch.no_grad():
    inputs = tokenizer(pairs, padding=True, truncation=True, return_tensors='pt', max_length=512)
    scores = model(**inputs, return_dict=True).logits.view(-1, ).float()
    print(scores)
```


## Evaluation  
`baai-general-embedding` æ¨¡å‹åœ¨MTEBå’ŒC-MTEBæ’è¡Œæ¦œä¸Šéƒ½å®ç°äº†**æœ€å…ˆè¿›çš„æ€§èƒ½**!
æ›´å¤šç»†èŠ‚å’Œè¯„ä¼°è„šæœ¬è¯·å‚è§ [C_MTEB](./C_MTEB). 

- **MTEB**:   

| Model Name | Dimension | Sequence Length | Average (56) | Retrieval (15) |Clustering (11) | Pair Classification (3) | Reranking (4) |  STS (10) | Summarization (1) | Classification (12) |
|:----:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|
| [**BAAI/bge-large-en-v1.5**](https://huggingface.co/BAAI/bge-large-en-v1.5) | 1024 | 512 |  **64.23** | **54.29** |  46.08 | 87.12 | 60.03 | 83.11 | 31.61 | 75.97 |  
| [**BAAI/bge-base-en-v1.5**](https://huggingface.co/BAAI/bge-base-en-v1.5) |  768 | 512 | 63.55 | 53.25 |   45.77 | 86.55 | 58.86 | 82.4 | 31.07 | 75.53 |  
| [**BAAI/bge-small-en-v1.5**](https://huggingface.co/BAAI/bge-small-en-v1.5) |  384 | 512 | 62.17 |51.68 | 43.82 |  84.92 | 58.36 | 81.59 | 30.12 | 74.14 |  
| [**bge-large-en**](https://huggingface.co/BAAI/bge-large-en) |  1024 | 512 | 63.98 |  53.9 | 46.98 | 85.8 | 59.48 | 81.56 | 32.06 | 76.21 | 
| [**bge-base-en**](https://huggingface.co/BAAI/bge-base-en) |  768 | 512 |  63.36 | 53.0 | 46.32 | 85.86 | 58.7 | 81.84 | 29.27 | 75.27 | 
| [gte-large](https://huggingface.co/thenlper/gte-large) |  1024 | 512 | 63.13 | 52.22 | 46.84 | 85.00 | 59.13 | 83.35 | 31.66 | 73.33 |
| [gte-base](https://huggingface.co/thenlper/gte-base) 	|  768 | 512 | 62.39 | 51.14 | 46.2 | 84.57 | 58.61 | 82.3 | 31.17 | 73.01 |
| [e5-large-v2](https://huggingface.co/intfloat/e5-large-v2) |  1024| 512 | 62.25 | 50.56 | 44.49 | 86.03 | 56.61 | 82.05 | 30.19 | 75.24 |
| [**bge-small-en**](https://huggingface.co/BAAI/bge-small-en) |  384 | 512 | 62.11 |  51.82 | 44.31 | 83.78 | 57.97 | 80.72 | 30.53 | 74.37 |  
| [instructor-xl](https://huggingface.co/hkunlp/instructor-xl) | 768 | 512 | 61.79 | 49.26 | 44.74 | 86.62 | 57.29 | 83.06 | 32.32 | 61.79 |
| [e5-base-v2](https://huggingface.co/intfloat/e5-base-v2) | 768 | 512 | 61.5 | 50.29 | 43.80 | 85.73 | 55.91 | 81.05 | 30.28 | 73.84 |
| [gte-small](https://huggingface.co/thenlper/gte-small) | 384 | 512 | 61.36 | 49.46 | 44.89 | 83.54 | 57.7 | 82.07 | 30.42 | 72.31 |
| [text-embedding-ada-002](https://platform.openai.com/docs/guides/embeddings) | 1536 | 8192 | 60.99 | 49.25 | 45.9 | 84.89 | 56.32 | 80.97 | 30.8 | 70.93 |
| [e5-small-v2](https://huggingface.co/intfloat/e5-base-v2) | 384 | 512 | 59.93 | 49.04 | 39.92 | 84.67 | 54.32 | 80.39 | 31.16 | 72.94 |
| [sentence-t5-xxl](https://huggingface.co/sentence-transformers/sentence-t5-xxl) | 768 | 512 | 59.51 | 42.24 | 43.72 | 85.06 | 56.42 | 82.63 | 30.08 | 73.42 |
| [all-mpnet-base-v2](https://huggingface.co/sentence-transformers/all-mpnet-base-v2) 	| 768 | 514 	| 57.78 | 43.81 | 43.69 | 83.04 | 59.36 | 80.28 | 27.49 | 65.07 |
| [sgpt-bloom-7b1-msmarco](https://huggingface.co/bigscience/sgpt-bloom-7b1-msmarco) 	 | 4096 | 2048 | 57.59 | 48.22 | 38.93 | 81.9 | 55.65 | 77.74 | 33.6 | 66.19 |
| [all-MiniLM-L12-v2](https://huggingface.co/sentence-transformers/all-MiniLM-L12-v2) 	| 384 | 512 	| 56.53 | 42.69 | 41.81 | 82.41 | 58.44 | 79.8 | 27.9 | 63.21 |
| [all-MiniLM-L6-v2](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2) 	 | 384 | 512 	| 56.26 | 41.95 | 42.35 | 82.37 | 58.04 | 78.9 | 30.81 | 63.05 |
| [contriever-base-msmarco](https://huggingface.co/nthakur/contriever-base-msmarco) 	| 768 | 512 	| 56.00 | 41.88 | 41.1 	| 82.54 | 53.14 | 76.51 | 30.36 | 66.68 |
| [sentence-t5-base](https://huggingface.co/sentence-transformers/sentence-t5-base) 	 | 768 | 512 	| 55.27 | 33.63 | 40.21 | 85.18 | 53.09 | 81.14 | 31.39 | 69.81 |



- **C-MTEB**:  

æˆ‘ä»¬å»ºç«‹äº†ä¸€ä¸ªä¸­æ–‡æ–‡æœ¬åµŒå…¥çš„åŸºå‡†æµ‹è¯•é›†åˆC-MTEBï¼Œå…¶åŒ…æ‹¬6ä¸ªä»»åŠ¡çš„31ä¸ªæ•°æ®é›†ã€‚ 
è¯·å‚é˜…[C_MTEB](C_MTEB/README.md)è·å–è¯¦ç»†ä»‹ç»ã€‚

| Model | Embedding dimension | Avg | Retrieval | STS | PairClassification | Classification | Reranking | Clustering |
|:-------------------------------|:--------:|:--------:|:--------:|:--------:|:--------:|:--------:|:--------:|:--------:|
| [**BAAI/bge-large-zh-v1.5**](https://huggingface.co/BAAI/bge-large-zh-v1.5) | 1024 |  **64.53** | 70.46 | 56.25 | 81.6 | 69.13 | 65.84 | 48.99 |  
| [BAAI/bge-base-zh-v1.5](https://huggingface.co/BAAI/bge-base-zh-v1.5) | 768 |  63.13 | 69.49 | 53.72 | 79.75 | 68.07 | 65.39 | 47.53 |  
| [BAAI/bge-small-zh-v1.5](https://huggingface.co/BAAI/bge-small-zh-v1.5) | 512 | 57.82 | 61.77 | 49.11 | 70.41 | 63.96 | 60.92 | 44.18 |   
| [BAAI/bge-large-zh](https://huggingface.co/BAAI/bge-large-zh) | 1024 | 64.20 | 71.53 | 54.98 | 78.94 | 68.32 | 65.11 | 48.39 |
| [bge-large-zh-noinstruct](https://huggingface.co/BAAI/bge-large-zh-noinstruct) | 1024 | 63.53 | 70.55 | 53 | 76.77 | **68.58** | 64.91 | **50.01** |
| [BAAI/bge-base-zh](https://huggingface.co/BAAI/bge-base-zh) | 768 | 62.96 | 69.53 | 54.12 | 77.5 | 67.07 | 64.91 | 47.63 |
| [multilingual-e5-large](https://huggingface.co/intfloat/multilingual-e5-large) | 1024 | 58.79 | 63.66 | 48.44 | 69.89 | 67.34 | 56.00 | 48.23 |
| [BAAI/bge-small-zh](https://huggingface.co/BAAI/bge-small-zh) | 512 | 58.27 |  63.07 | 49.45 | 70.35 | 63.64 | 61.48 | 45.09 |
| [m3e-base](https://huggingface.co/moka-ai/m3e-base) | 768 | 57.10 | 56.91 | 50.47 | 63.99 | 67.52 | 59.34 | 47.68 |
| [m3e-large](https://huggingface.co/moka-ai/m3e-large) | 1024 |  57.05 | 54.75 | 50.42 | 64.3 | 68.2 | 59.66 | 48.88 |
| [multilingual-e5-base](https://huggingface.co/intfloat/multilingual-e5-base) | 768 | 55.48 | 61.63 | 46.49 | 67.07 | 65.35 | 54.35 | 40.68 |
| [multilingual-e5-small](https://huggingface.co/intfloat/multilingual-e5-small) | 384 | 55.38 | 59.95 | 45.27 | 66.45 | 65.85 | 53.86 | 45.26 |
| [text-embedding-ada-002(OpenAI)](https://platform.openai.com/docs/guides/embeddings/what-are-embeddings) | 1536 |  53.02 | 52.0 | 43.35 | 69.56 | 64.31 | 54.28 | 45.68 |
| [luotuo](https://huggingface.co/silk-road/luotuo-bert-medium) | 1024 | 49.37 |  44.4 | 42.78 | 66.62 | 61 | 49.25 | 44.39 |
| [text2vec-base](https://huggingface.co/shibing624/text2vec-base-chinese) | 768 |  47.63 | 38.79 | 43.41 | 67.41 | 62.19 | 49.45 | 37.66 |
| [text2vec-large](https://huggingface.co/GanymedeNil/text2vec-large-chinese) | 1024 | 47.36 | 41.94 | 44.97 | 70.86 | 60.66 | 49.16 | 30.02 |

æ‰€æœ‰çš„æ¨¡å‹æ–‡ä»¶éƒ½å·²ä¸Šä¼ åˆ°huggingfaceä¸Šï¼š https://huggingface.co/BAAI. 
å¦‚æœä½ æ— æ³•è¿æ¥åˆ°huggingface,å¯ä»¥é€šè¿‡æ™ºæºç½‘ç«™è¿›è¡Œä¸‹è½½ï¼š https://model.baai.ac.cn/models .


- **Reranking**:
è¯„ä¼°è„šæœ¬å‚è€ƒ [C_MTEB](https://github.com/FlagOpen/FlagEmbedding/blob/master/C_MTEB/).

| Model | T2Reranking | T2RerankingZh2En\* | T2RerankingEn2Zh\* | MMarcoReranking | CMedQAv1 | CMedQAv2 | Avg |  
|:-------------------------------|:--------:|:--------:|:--------:|:--------:|:--------:|:--------:|:--------:|  
| text2vec-base-multilingual | 64.66 | 62.94 | 62.51 | 14.37 | 48.46 | 48.6 | 50.26 |  
| multilingual-e5-small | 65.62 | 60.94 | 56.41 | 29.91 | 67.26 | 66.54 | 57.78 |  
| multilingual-e5-large | 64.55 | 61.61 | 54.28 | 28.6 | 67.42 | 67.92 | 57.4 |  
| multilingual-e5-base | 64.21 | 62.13 | 54.68 | 29.5 | 66.23 | 66.98 | 57.29 |  
| m3e-base | 66.03 | 62.74 | 56.07 | 17.51 | 77.05 | 76.76 | 59.36 |  
| m3e-large | 66.13 | 62.72 | 56.1 | 16.46 | 77.76 | 78.27 | 59.57 |  
| bge-base-zh-v1.5 | 66.49 | 63.25 | 57.02 | 29.74 | 80.47 | 84.88 | 63.64 |  
| bge-large-zh-v1.5 | 65.74 | 63.39 | 57.03 | 28.74 | 83.45 | 85.44 | 63.97 |  
| [BAAI/bge-reranker-base](https://huggingface.co/BAAI/bge-reranker-base) | 67.28 | 63.95 | 60.45 | 35.46 | 81.26 | 84.1 | 65.42 |  
| [BAAI/bge-reranker-large](https://huggingface.co/BAAI/bge-reranker-large) | 67.6 | 64.03 | 61.44 | 37.16 | 82.15 | 84.18 | 66.09 |  

\* : T2RerankingZh2En æ˜¯è·¨è¯­è¨€æ£€ç´¢æ•°æ®é›†ï¼Œä½¿ç”¨ä¸­æ–‡æ£€ç´¢è‹±æ–‡ï¼Œ T2RerankingEn2Zhæ˜¯ä½¿ç”¨è‹±æ–‡æ£€ç´¢ä¸­æ–‡ã€‚


## Train

### BAAI Embedding 


æˆ‘ä»¬ä½¿ç”¨[retromae](https://github.com/staoxiao/RetroMAE) å¯¹æ¨¡å‹è¿›è¡Œé¢„è®­ç»ƒï¼Œå†ç”¨å¯¹æ¯”å­¦ä¹ åœ¨å¤§è§„æ¨¡æˆå¯¹æ•°æ®ä¸Šè®­ç»ƒæ¨¡å‹ã€‚
**ä½ å¯ä»¥æŒ‰ç…§æˆ‘ä»¬çš„[ç¤ºä¾‹](https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune) åœ¨æœ¬åœ°æ•°æ®ä¸Šå¾®è°ƒåµŒå…¥æ¨¡å‹ã€‚**
æˆ‘ä»¬è¿˜æä¾›äº†ä¸€ä¸ª[é¢„è®­ç»ƒç¤ºä¾‹](https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/pretrain) ã€‚
è¯·æ³¨æ„ï¼Œé¢„è®­ç»ƒçš„ç›®æ ‡æ˜¯é‡æ„æ–‡æœ¬ï¼Œé¢„è®­ç»ƒåçš„æ¨¡å‹æ— æ³•ç›´æ¥ç”¨äºç›¸ä¼¼åº¦è®¡ç®—ï¼Œéœ€è¦è¿›è¡Œå¾®è°ƒä¹‹åæ‰å¯ä»¥ç”¨äºç›¸ä¼¼åº¦è®¡ç®—ã€‚
æ›´å¤šå…³äºbgeçš„è®­ç»ƒæƒ…å†µè¯·å‚é˜…[baai_general_embedding](https://github.com/FlagOpen/FlagEmbedding/blob/master/FlagEmbedding/baai_general_embedding/README.md) ï¼Œ


### BGE Reranker

äº¤å‰ç¼–ç å™¨å°†å¯¹æŸ¥è¯¢å’Œç­”æ¡ˆå®æ—¶è®¡ç®—ç›¸å…³æ€§åˆ†æ•°ï¼Œè¿™æ¯”å‘é‡æ¨¡å‹(å³åŒç¼–ç å™¨)æ›´å‡†ç¡®ï¼Œä½†æ¯”å‘é‡æ¨¡å‹æ›´è€—æ—¶ã€‚
å› æ­¤ï¼Œå®ƒå¯ä»¥ç”¨æ¥å¯¹åµŒå…¥æ¨¡å‹è¿”å›çš„å‰kä¸ªæ–‡æ¡£é‡æ–°æ’åºã€‚
æˆ‘ä»¬åœ¨å¤šè¯­è¨€æ•°æ®ä¸Šè®­ç»ƒäº†äº¤å‰ç¼–ç å™¨ï¼Œæ•°æ®æ ¼å¼ä¸å‘é‡æ¨¡å‹ç›¸åŒï¼Œå› æ­¤æ‚¨å¯ä»¥æ ¹æ®æˆ‘ä»¬çš„[ç¤ºä¾‹](https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/reranker) è½»æ¾åœ°å¯¹å…¶è¿›è¡Œå¾®è°ƒã€‚
æ›´å¤šç»†èŠ‚è¯·å‚è€ƒ[./FlagEmbedding/reranker/README.md](https://github.com/FlagOpen/FlagEmbedding/blob/master/FlagEmbedding/reranker/README.md)

 

## Contact
å¦‚æœæ‚¨æœ‰ä»»åŠ¡ç–‘é—®æˆ–è€…å»ºè®®ï¼Œæ¬¢è¿æäº¤issueå’ŒPR, 
ä¹Ÿå¯ä»¥å‘é€é‚®ä»¶ç»™ Shitao Xiao(stxiao@baai.ac.cn) and  Zheng Liu(liuzheng@baai.ac.cn). 


## Citation

å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„å·¥ä½œæœ‰æ‰€å¸®åŠ©ï¼Œè¯·è€ƒè™‘ç‚¹ä¸ªæ˜Ÿ :star: å’Œå¼•ç”¨ä»¥ä¸‹è®ºæ–‡:
```
@misc{bge_embedding,
      title={C-Pack: Packaged Resources To Advance General Chinese Embedding}, 
      author={Shitao Xiao and Zheng Liu and Peitian Zhang and Niklas Muennighoff},
      year={2023},
      eprint={2309.07597},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
```

## License
FlagEmbeddingåŸºäº[MIT License](LICENSE)å¼€æºåè®®ã€‚å‘å¸ƒçš„æ¨¡å‹æƒé‡å¯å•†ç”¨ã€‚



