
<!DOCTYPE html>


<html lang="en" data-content_root="../" data-theme="light">

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-X4B1E1Q35K"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'G-X4B1E1Q35K');
    </script>
    
    <title>BGE-VL &#8212; BGE  documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "light";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=a746c00c" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../_static/css/custom.css?v=aace3583" />
  
  <!-- So that users can add custom icons -->
  <script src="../_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="../_static/documentation_options.js?v=5929fcd5"></script>
    <script src="../_static/doctools.js?v=9bcbadda"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'bge/bge_vl';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="BGE-Code-v1" href="bge_code.html" />
    <link rel="prev" title="BGE-EN-ICL" href="bge_icl.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="light">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class="col-lg-3 navbar-header-items__start">
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    
    
    
    <img src="../_static/bge_logo.jpeg" class="logo__image only-light" alt=""/>
    <img src="../_static/bge_logo.jpeg" class="logo__image only-dark pst-js-only" alt=""/>
  
  
    <p class="title logo__title">BGE</p>
  
</a></div>
    
  </div>
  
  <div class="col-lg-9 navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../index.html">
    Home
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../Introduction/index.html">
    Introduction
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="index.html">
    BGE
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../tutorial/index.html">
    Tutorials
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../API/index.html">
    API
  </a>
</li>

            <li class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button"
                data-bs-toggle="dropdown" aria-expanded="false"
                aria-controls="pst-nav-more-links">
                    More
                </button>
                <ul id="pst-nav-more-links" class="dropdown-menu">
                    
<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../FAQ/index.html">
    FAQ
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../community/index.html">
    Community
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-external" href="https://huggingface.co/collections/BAAI/bge-66797a74476eb1f085c7446d">
    HF Models
  </a>
</li>

                </ul>
            </li>
            
  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
        </div>
      
      
        <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/FlagOpen/FlagEmbedding" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://pypi.org/project/FlagEmbedding/" title="PyPI" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-python fa-lg" aria-hidden="true"></i>
            <span class="sr-only">PyPI</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://huggingface.co/collections/BAAI/bge-66797a74476eb1f085c7446d" title="HF Models" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-solid fa-cube fa-lg" aria-hidden="true"></i>
            <span class="sr-only">HF Models</span></a>
        </li>
</ul></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
    </div>
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="On this page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../index.html">
    Home
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../Introduction/index.html">
    Introduction
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="index.html">
    BGE
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../tutorial/index.html">
    Tutorials
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../API/index.html">
    API
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../FAQ/index.html">
    FAQ
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../community/index.html">
    Community
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-external" href="https://huggingface.co/collections/BAAI/bge-66797a74476eb1f085c7446d">
    HF Models
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/FlagOpen/FlagEmbedding" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://pypi.org/project/FlagEmbedding/" title="PyPI" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-python fa-lg" aria-hidden="true"></i>
            <span class="sr-only">PyPI</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://huggingface.co/collections/BAAI/bge-66797a74476eb1f085c7446d" title="HF Models" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-solid fa-cube fa-lg" aria-hidden="true"></i>
            <span class="sr-only">HF Models</span></a>
        </li>
</ul></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
<nav class="bd-docs-nav bd-links"
     aria-label="Section Navigation">
  <p class="bd-links__title" role="heading" aria-level="1">Section Navigation</p>
  <div class="bd-toc-item navbar-nav"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Embedder</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="bge_v1_v1.5.html">BGE v1 &amp; v1.5</a></li>
<li class="toctree-l1"><a class="reference internal" href="bge_m3.html">BGE-M3</a></li>
<li class="toctree-l1"><a class="reference internal" href="bge_icl.html">BGE-EN-ICL</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">BGE-VL</a></li>
<li class="toctree-l1"><a class="reference internal" href="bge_code.html">BGE-Code-v1</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Reranker</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="bge_reranker.html">BGE-Reranker</a></li>
<li class="toctree-l1"><a class="reference internal" href="bge_reranker_v2.html">BGE-Reranker-v2</a></li>
</ul>
</div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">

<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="index.html" class="nav-link">BGE</a></li>
    
    <li class="breadcrumb-item active" aria-current="page"><span class="ellipsis">BGE-VL</span></li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="bge-vl">
<h1>BGE-VL<a class="headerlink" href="#bge-vl" title="Link to this heading">#</a></h1>
<p>BGE-VL is a series of multimodel retrieval models training on <a class="reference external" href="https://github.com/VectorSpaceLab/MegaPairs">MegaPairs</a></p>
<p>BGE-VL contains light weight CLIP based models as well as more powerful LLAVA-NeXT based MLLM models:</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Model</p></th>
<th class="head"><p>Language</p></th>
<th class="head"><p>Parameters</p></th>
<th class="head"><p>Model Size</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><a class="reference external" href="https://huggingface.co/BAAI/BGE-VL-base">BAAI/bge-vl-base</a></p></td>
<td><p>English</p></td>
<td><p>150M</p></td>
<td><p>299 MB</p></td>
<td><p>Light weight multimodel embedder among image and text</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference external" href="https://huggingface.co/BAAI/BGE-VL-large">BAAI/bge-vl-large</a></p></td>
<td><p>English</p></td>
<td><p>428M</p></td>
<td><p>855 MB</p></td>
<td><p>Large scale multimodel embedder among image and text</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference external" href="https://huggingface.co/BAAI/BGE-VL-MLLM-S1">BAAI/bge-vl-MLLM-S1</a></p></td>
<td><p>English</p></td>
<td><p>7.57B</p></td>
<td><p>15.14 GB</p></td>
<td><p>SOTA in composed image retrieval, trained on MegaPairs dataset</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference external" href="https://huggingface.co/BAAI/BGE-VL-MLLM-S2">BAAI/bge-vl-MLLM-S2</a></p></td>
<td><p>English</p></td>
<td><p>7.57B</p></td>
<td><p>15.14 GB</p></td>
<td><p>Finetune BGE-VL-MLLM-S1 with one epoch on MMEB training set</p></td>
</tr>
</tbody>
</table>
</div>
<div class="line-block">
<div class="line"><a class="reference external" href="https://huggingface.co/BAAI/BGE-VL-MLLM-S2">BAAI/bge-vl-MLLM-S2</a>  |  English  |    7.57B   |   15.14 GB   |   Finetune BGE-VL-MLLM-S1 with one epoch on MMEB training set         |</div>
</div>
<section id="bge-vl-clip">
<h2>BGE-VL-CLIP<a class="headerlink" href="#bge-vl-clip" title="Link to this heading">#</a></h2>
<p>The base and large model are trained based on CLIP-vit-base-patch16 and CLIP-vit-large-patch14.
For composed image-text data, the model directly use score-fusion to sum up the outputs of visual encoder and text encoder and get the final embedding.</p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>Our code works well on transformers==4.45.2, and we recommend using this version.</p>
</div>
<p>You can easily use BGE-VL-CLIP models based on transformers:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoModel</span>

<span class="n">MODEL_NAME</span> <span class="o">=</span> <span class="s2">&quot;BAAI/BGE-VL-base&quot;</span> <span class="c1"># or &quot;BAAI/BGE-VL-large&quot;</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">MODEL_NAME</span><span class="p">,</span> <span class="n">trust_remote_code</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="c1"># You must set trust_remote_code=True</span>
<span class="n">model</span><span class="o">.</span><span class="n">set_processor</span><span class="p">(</span><span class="n">MODEL_NAME</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">query</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span>
        <span class="n">images</span> <span class="o">=</span> <span class="s2">&quot;./assets/cir_query.png&quot;</span><span class="p">,</span>
        <span class="n">text</span> <span class="o">=</span> <span class="s2">&quot;Make the background dark, as if the camera has taken the photo at night&quot;</span>
    <span class="p">)</span>
    <span class="n">candidates</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span>
        <span class="n">images</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;./assets/cir_candi_1.png&quot;</span><span class="p">,</span> <span class="s2">&quot;./assets/cir_candi_2.png&quot;</span><span class="p">]</span>
    <span class="p">)</span>

    <span class="n">scores</span> <span class="o">=</span> <span class="n">query</span> <span class="o">@</span> <span class="n">candidates</span><span class="o">.</span><span class="n">T</span>
<span class="nb">print</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="bge-vl-mllm">
<h2>BGE-VL-MLLM<a class="headerlink" href="#bge-vl-mllm" title="Link to this heading">#</a></h2>
<p>The multimodal large language models (MLLMs) incorporate a visual encoder, typically based on a vision transformer, into a large language model (LLM).
This integration allows image tokens to be directly processed by the LLM.
Consequently, MLLMs can effectively handle diverse multimodal inputs by converting any type of input into a sequence of tokens.</p>
<p>BGE-VL-MLLM builds upon the LLaVA1.6. In both training and inference stages, MMRet uses task-specific instructions for query inputs to improve generalization, aligning
with standard practices in LLM-based embedding models.
A typical multimodal query input is structured as follows:</p>
<div class="math notranslate nohighlight">
\[⟨\text{instruct}⟩{\{task\_ inst\}} \space⟨\text{query}⟩\{q_t\} \{q_i\}\space[\text{EOS}]\]</div>
<p>where <span class="math notranslate nohighlight">\({task_inst}\)</span> represents the task-specific instruction, <span class="math notranslate nohighlight">\({qt}\)</span> denotes the input query text, and
<span class="math notranslate nohighlight">\({qi}\)</span> is the input query image.
The normalized last hidden state of the [EOS] token in the MLLM is used as the embedding of any given input sequence.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoModel</span>
<span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>

<span class="n">MODEL_NAME</span><span class="o">=</span> <span class="s2">&quot;BAAI/BGE-VL-MLLM-S1&quot;</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">MODEL_NAME</span><span class="p">,</span> <span class="n">trust_remote_code</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>

<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">model</span><span class="o">.</span><span class="n">set_processor</span><span class="p">(</span><span class="n">MODEL_NAME</span><span class="p">)</span>

    <span class="n">query_inputs</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">data_process</span><span class="p">(</span>
        <span class="n">text</span><span class="o">=</span><span class="s2">&quot;Make the background dark, as if the camera has taken the photo at night&quot;</span><span class="p">,</span>
        <span class="n">images</span><span class="o">=</span><span class="s2">&quot;./assets/cir_query.png&quot;</span><span class="p">,</span>
        <span class="n">q_or_c</span><span class="o">=</span><span class="s2">&quot;q&quot;</span><span class="p">,</span>
        <span class="n">task_instruction</span><span class="o">=</span><span class="s2">&quot;Retrieve the target image that best meets the combined criteria by using both the provided image and the image retrieval instructions: &quot;</span>
    <span class="p">)</span>
    <span class="n">candidate_inputs</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">data_process</span><span class="p">(</span>
        <span class="n">images</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;./assets/cir_candi_1.png&quot;</span><span class="p">,</span> <span class="s2">&quot;./assets/cir_candi_2.png&quot;</span><span class="p">],</span>
        <span class="n">q_or_c</span><span class="o">=</span><span class="s2">&quot;c&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">query_embs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">query_inputs</span><span class="p">,</span> <span class="n">output_hidden_states</span><span class="o">=</span><span class="kc">True</span><span class="p">)[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span>
    <span class="n">candi_embs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">candidate_inputs</span><span class="p">,</span> <span class="n">output_hidden_states</span><span class="o">=</span><span class="kc">True</span><span class="p">)[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span>

    <span class="n">query_embs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">query_embs</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">candi_embs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">candi_embs</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

    <span class="n">scores</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">query_embs</span><span class="p">,</span> <span class="n">candi_embs</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="bge-vl-v1-5">
<h2>BGE-VL-v1.5<a class="headerlink" href="#bge-vl-v1-5" title="Link to this heading">#</a></h2>
<p>BGE-VL-v1.5 series is the updated version of BGE-VL, bringing better performance on both retrieval and multi-modal understanding. The models were trained on 30M MegaPairs data and extra 10M natural and synthetic data.</p>
<p><cite>bge-vl-v1.5-zs</cite> is a zero-shot model, only trained on the data mentioned above. <cite>bge-vl-v1.5-mmeb</cite> is the fine-tuned version on MMEB training set.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoModel</span>
<span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>

<span class="n">MODEL_NAME</span><span class="o">=</span> <span class="s2">&quot;BAAI/BGE-VL-v1.5-mmeb&quot;</span> <span class="c1"># &quot;BAAI/BGE-VL-v1.5-zs&quot;</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">MODEL_NAME</span><span class="p">,</span> <span class="n">trust_remote_code</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>

<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">model</span><span class="o">.</span><span class="n">set_processor</span><span class="p">(</span><span class="n">MODEL_NAME</span><span class="p">)</span>

    <span class="n">query_inputs</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">data_process</span><span class="p">(</span>
        <span class="n">text</span><span class="o">=</span><span class="s2">&quot;Make the background dark, as if the camera has taken the photo at night&quot;</span><span class="p">,</span>
        <span class="n">images</span><span class="o">=</span><span class="s2">&quot;../../imgs/cir_query.png&quot;</span><span class="p">,</span>
        <span class="n">q_or_c</span><span class="o">=</span><span class="s2">&quot;q&quot;</span><span class="p">,</span>
        <span class="n">task_instruction</span><span class="o">=</span><span class="s2">&quot;Retrieve the target image that best meets the combined criteria by using both the provided image and the image retrieval instructions: &quot;</span>
    <span class="p">)</span>

    <span class="n">candidate_inputs</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">data_process</span><span class="p">(</span>
        <span class="n">images</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;../../imgs/cir_candi_1.png&quot;</span><span class="p">,</span> <span class="s2">&quot;../../imgs/cir_candi_2.png&quot;</span><span class="p">],</span>
        <span class="n">q_or_c</span><span class="o">=</span><span class="s2">&quot;c&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">query_embs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">query_inputs</span><span class="p">,</span> <span class="n">output_hidden_states</span><span class="o">=</span><span class="kc">True</span><span class="p">)[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span>
    <span class="n">candi_embs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">candidate_inputs</span><span class="p">,</span> <span class="n">output_hidden_states</span><span class="o">=</span><span class="kc">True</span><span class="p">)[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span>

    <span class="n">query_embs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">query_embs</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">candi_embs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">candi_embs</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

    <span class="n">scores</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">query_embs</span><span class="p">,</span> <span class="n">candi_embs</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
</pre></div>
</div>
<p>For more details, check out the repo of <a class="reference external" href="https://github.com/VectorSpaceLab/MegaPairs">MegaPairs</a></p>
</section>
</section>


                </article>
              
              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="bge_icl.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">BGE-EN-ICL</p>
      </div>
    </a>
    <a class="right-next"
       href="bge_code.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">BGE-Code-v1</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bge-vl-clip">BGE-VL-CLIP</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bge-vl-mllm">BGE-VL-MLLM</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bge-vl-v1-5">BGE-VL-v1.5</a></li>
</ul>
  </nav></div>

  <div class="sidebar-secondary-item">
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="../_sources/bge/bge_vl.rst.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      © Copyright 2024, BAAI.
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">

  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 8.2.3.
    <br/>
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  <!-- # L10n: Setting the PST URL as an argument as this does not need to be localized -->
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.16.1.
</p></div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>