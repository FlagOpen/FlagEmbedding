{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Faiss Quantizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will introduce the quantizer object in Faiss and how to use them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For CPU usage, run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For GPU on Linux x86_64 system, use Conda:\n",
    "\n",
    "```conda install -c pytorch -c nvidia faiss-gpu=1.8.0```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(768)\n",
    "\n",
    "data = np.random.random((1000, 128))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Scalar Quantizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normal data type of vector embeedings is usually 32 bit floats. Scalar quantization is transforming the 32 float representation to, for example, 8 bit interger. Thus with a 4x reduction in size. In this way, it can be seen as we distribute each dimension into 256 buckets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Name | Class | Parameters |\n",
    "|:------------:|:--------:|:-----------|\n",
    "| `ScalarQuantizer` | Quantizer class | `d`: dimension of vectors<br>`qtype`: map dimension into $2^\\text{qtype}$ clusters |\n",
    "| `IndexScalarQuantizer` | Flat index class | `d`: dimension of vectors<br>`qtype`: map dimension into $2^\\text{qtype}$ clusters<br>`metric`: similarity metric (L2 or IP) |\n",
    "| `IndexIVFScalarQuantizer` | IVF index class | `d`: dimension of vectors<br>`nlist`: number of cells/clusters to partition the inverted file space<br>`qtype`: map dimension into $2^\\text{qtype}$ clusters<br>`metric`: similarity metric (L2 or IP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantizer class objects are used to compress the data before adding into indexes. Flat index class objects and IVF index class objects can be used direct as and index. Quantization will be done automatically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scalar Quantizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[156 180  46 226  13 130  41 187  63 251  16 199 205 166 117 122 214   2\n",
      " 206 137  71 186  20 131  59  57  68 114  35  45  28 210  27  93  74 245\n",
      " 167   5  32  42  44 128  10 189  10  13  42 162 179 221 241 104 205  21\n",
      "  70  87  52 219 172 138 193   0 228 175 144  34  59  88 170   1 233 220\n",
      "  20  64 245 241   5 161  41  55  30 247 107   8 229  90 201  10  43 158\n",
      " 238 184 187 114 232  90 116 205  14 214 135 158 237 192 205 141 232 176\n",
      " 124 176 163  68  49  91 125  70   6 170  55  44 215  84  46  48 218  56\n",
      " 107 176]\n"
     ]
    }
   ],
   "source": [
    "d = 128\n",
    "qtype = faiss.ScalarQuantizer.QT_8bit\n",
    "\n",
    "quantizer = faiss.ScalarQuantizer(d, qtype)\n",
    "\n",
    "quantizer.train(data)\n",
    "new_data = quantizer.compute_codes(data)\n",
    "\n",
    "print(new_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scalar Quantizer Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 128\n",
    "k = 3\n",
    "qtype = faiss.ScalarQuantizer.QT_8bit\n",
    "# nlist = 5\n",
    "\n",
    "index = faiss.IndexScalarQuantizer(d, qtype, faiss.METRIC_L2)\n",
    "# index = faiss.IndexIVFScalarQuantizer(d, nlist, faiss.ScalarQuantizer.QT_8bit, faiss.METRIC_L2)\n",
    "\n",
    "index.train(data)\n",
    "index.add(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "closest elements: [[  0 471 188]]\n",
      "distance: [[1.6511828e-04 1.6252808e+01 1.6658131e+01]]\n"
     ]
    }
   ],
   "source": [
    "D, I = index.search(data[:1], k)\n",
    "\n",
    "print(f\"closest elements: {I}\")\n",
    "print(f\"distance: {D}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Product Quantizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When speed and memory are crucial factors in searching, product quantizer becomes a top choice. It is one of the effective quantizer on reducing memory size. \n",
    "\n",
    "The first step of PQ is dividing the original vectors with dimension `d` into smaller, low-dimensional sub-vectors with dimension `d/m`. Here `m` is the number of sub-vectors.\n",
    "\n",
    "Then clustering algorithms are used to create codebook of a fixed number of centroids.\n",
    "\n",
    "Next, each sub-vector of a vector is replaced by the index of the closest centroid from its corresponding codebook. Now each vector will be stored with only the indices instead of the full vector.\n",
    "\n",
    "When comuputing the distance between a query vector. Only the distances to the centroids in the codebooks are calculated, thus enable the quick approximate nearest neighbor searches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Name | Class | Parameters |\n",
    "|:------------:|:--------:|:-----------|\n",
    "| `ProductQuantizer` | Quantizer class | `d`: dimension of vectors<br>`M`: number of sub-vectors that D % M == 0<br>`nbits`: number of bits per subquantizer, so each contain $2^\\text{nbits}$ centroids |\n",
    "| `IndexPQ` | Flat index class | `d`: dimension of vectors<br>`M`: number of sub-vectors that D % M == 0<br>`nbits`: number of bits per subquantizer, so each contain $2^\\text{nbits}$ centroids<br>`metric`: similarity metric (L2 or IP) |\n",
    "| `IndexIVFPQ` | IVF index class | `quantizer`: the quantizer used in computing distance phase.<br>`d`: dimension of vectors<br>`nlist`: number of cells/clusters to partition the inverted file space<br>`M`: number of sub-vectors that D % M == 0<br>`nbits`: number of bits per subquantizer, so each contain $2^\\text{nbits}$ centroids<br>`metric`: similarity metric (L2 or IP) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Product Quantizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255\n",
      "[[ 90 169 226  45]\n",
      " [ 33  51  34  15]]\n"
     ]
    }
   ],
   "source": [
    "d = 128\n",
    "M = 8\n",
    "nbits = 4\n",
    "\n",
    "quantizer = faiss.ProductQuantizer(d, M, nbits)\n",
    "\n",
    "quantizer.train(data)\n",
    "new_data = quantizer.compute_codes(data)\n",
    "\n",
    "print(new_data.max())\n",
    "print(new_data[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Product Quantizer Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = faiss.IndexPQ(d, M, nbits, faiss.METRIC_L2)\n",
    "\n",
    "index.train(data)\n",
    "index.add(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "closest elements: [[  0 946 330]]\n",
      "distance: [[ 8.823908 11.602461 11.746731]]\n"
     ]
    }
   ],
   "source": [
    "D, I = index.search(data[:1], k)\n",
    "\n",
    "print(f\"closest elements: {I}\")\n",
    "print(f\"distance: {D}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Product Quantizer IVF Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlist = 5\n",
    "\n",
    "quantizer = faiss.IndexFlat(d, faiss.METRIC_L2)\n",
    "index = faiss.IndexIVFPQ(quantizer, d, nlist, M, nbits, faiss.METRIC_L2)\n",
    "\n",
    "index.train(data)\n",
    "index.add(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "closest elements: [[  0 899 521]]\n",
      "distance: [[ 8.911423 12.088312 12.104569]]\n"
     ]
    }
   ],
   "source": [
    "D, I = index.search(data[:1], k)\n",
    "\n",
    "print(f\"closest elements: {I}\")\n",
    "print(f\"distance: {D}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
